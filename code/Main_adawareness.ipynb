{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main_adawareness.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kgV0wQdK9es5"},"source":["# AdAwareness\n","\n","---\n","\n","\n","\n","---\n","\n","\n","Clone https://github.com/irisong980912/gender_bias"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9xqgatT99es9"},"source":["# Import Datasets\n","\n","## Youtube8M videos\n","\n","Follow the instructions from here https://github.com/gsssrao/youtube-8m-videos-frames\n","\n","  » Download youtube-dl and ffmpeg\n","  \n","  » Create a txt file selectedcategories.txt with 'Television advertisement' in the first line and a second blank line.\n","  \n","  » bash downloadmulticategoryvideos.sh 0 selectedcategories.txt\n","  \n","  ## Pittsburg videos\n","  \n","  Follow instructions in the github  Readme"]},{"cell_type":"markdown","metadata":{"id":"AtvLP0VJDtyU","colab_type":"text"},"source":["  # Extract frames\n","  \n"," bash extract_frames.sh \n"," \n"," (you might need to change the path) \n","\n","\n","https://github.com/irisong980912/gender_bias/blob/master/extract_frames.sh"]},{"cell_type":"markdown","metadata":{"id":"eD5NkBH2k2M6","colab_type":"text"},"source":["# DeepAI Nudity Detector"]},{"cell_type":"markdown","metadata":{"id":"ienI61Pt9saV","colab_type":"text"},"source":["python3 nudity.py -» Google Drive"]},{"cell_type":"markdown","metadata":{"id":"QBjeWjVU1O-1","colab_type":"text"},"source":["# Algorithmia "]},{"cell_type":"code","metadata":{"id":"z_AFDaoGmyT7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaJf_jeoEQ8V","colab_type":"code","colab":{}},"source":["import time\n","\n","import platform\n","import io\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import cm \n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXtsFeHfIJcc","colab_type":"code","colab":{}},"source":["import torchvision.models as models\n","\n","import os\n","from google.colab import files\n","import numpy as np\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C0VHGm5y8wx0","colab_type":"code","colab":{}},"source":["# TODO: read the image label input\n","  # - maybe need to change image file format? (ask Jean-Philip)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-aMwVDE6Ayb6","colab_type":"code","colab":{}},"source":["# TODO: perform the "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uEfhUm9I9E65","colab_type":"text"},"source":["###Video title preprocessing\n","\n","\n","1.   Bags of  words / Tokenizer?\n","2.   Sequence padding?\n","3.   Word2vec or an embedding layer before the lstm layer?\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ZfcArveJTHK7","colab_type":"code","colab":{}},"source":["def prepare_sequence():\n","  pass"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yaiDVt_wOmw6","colab_type":"text"},"source":["##DATASET PREPROCESSING"]},{"cell_type":"code","metadata":{"id":"WmJBXxmBAwTz","colab_type":"code","colab":{}},"source":["import os\n","import math\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import numpy as np\n","import torch.utils.data\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score\n","from torchvision.transforms import ToTensor\n","\n","from torch.utils.data.sampler import SubsetRandomSampler"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rqcas-PBl43","colab_type":"code","colab":{}},"source":["use_gpu = torch.cuda.is_available()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdmOwGVswwE7","colab_type":"code","colab":{}},"source":["def make_dir(file_path):\n","    if not os.path.exists(file_path):\n","        os.makedirs(file_path)\n","\n","def separate_train_test(dataset_path, train_path, test_path, test_split=0.2, extension = \".png\"):\n","    class_index = 1\n","    for classname in sorted(os.listdir(dataset_path)):\n","        make_dir(os.path.join(train_path, classname))\n","        make_dir(os.path.join(test_path, classname))\n","        i = 0\n","        for file in sorted(os.listdir(os.path.join(dataset_path, classname))):\n","            if file.endswith(extension):\n","                continue\n","            classname_path = os.path.join(dataset_path, classname)\n","            file_path = os.path.join(dataset_path, classname, file)\n","            if i < len(os.listdir(classname_path)) * test_split:\n","                copyfile(file_path, os.path.join(test_path, classname, file))\n","            else:\n","                copyfile(file_path, os.path.join(train_path, classname, file))\n","            i += 1\n","\n","        class_index += 1\n","\n","#TODO\n","\n","def attribute_labels(datset_path):\n","  pass\n","      \n","  \n","def train_valid_loaders(dataset, batch_size, train_split=0.8, shuffle=True):\n","    num_data = len(dataset)\n","    indices = np.arange(num_data)\n","\n","    if shuffle:\n","        np.random.shuffle(indices)\n","\n","    split = math.floor(train_split * num_data)\n","    train_idx, valid_idx = indices[:split], indices[split:]\n","\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","    train_loader = torch.utils.data.DataLoader(dataset,\n","                                               batch_size=batch_size, sampler=train_sampler)\n","   \n","    valid_loader = torch.utils.data.DataLoader(dataset,\n","                                               batch_size=batch_size, sampler=valid_sampler)\n","\n","    return train_loader, valid_loader\n","  \n","  \n","def train_test_valid_loaders(train_path, test_path, train_split, transformer):\n","\n","    train_dt = ImageFolder(root=train_path, transform=transformer)\n","    test_dt = ImageFolder(root=test_path, transform=transformer)\n","    train_loader, val_loader = train_valid_loaders(train_dt, batch_size=batch_size, train_split=train_split)\n","    test_loader, _= train_valid_loaders(dataset, batch_size, train_split=1)\n","    \n","    return train_loader, test_loader, valid_loader\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UCJKC7RAPTeZ","colab_type":"code","colab":{}},"source":["dataset_path=\n","train_path=\n","test_path =  #TODO\n","test_split=\n","transformer = \n","\n","separate_train_test(dataset_path, train_path, test_path, test_split=test_split)\n","\n","attribute_labels(datset_path)\n","\n","train_loader, test_loader, valid_loader = train_test_valid_loaders(train_path, test_path, train_split, transformer)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVLb5Jsy2xPh","colab_type":"code","colab":{}},"source":["class History:\n","\n","    def __init__(self):\n","        self.history = {\n","            'train_acc': [],\n","            'val_acc': [],\n","            'train_loss': [],\n","            'val_loss': []\n","        }\n","\n","    def save(self, train_acc, val_acc, train_loss, val_loss):\n","        self.history['train_acc'].append(train_acc)\n","        self.history['val_acc'].append(val_acc)\n","        self.history['train_loss'].append(train_loss)\n","        self.history['val_loss'].append(val_loss)\n","\n","    def display(self, save):\n","        epoch = len(self.history['train_acc'])\n","        epochs = [x for x in range(1, epoch + 1)]\n","\n","        fig, axes = plt.subplots(2, 1)\n","        plt.tight_layout()\n","\n","        axes[0].set_title('Train accuracy')\n","        axes[0].set_xlabel('Epochs')\n","        axes[0].set_ylabel('Accuracy')\n","        axes[0].plot(epochs, self.history['train_acc'], label='Train')\n","        axes[0].plot(epochs, self.history['val_acc'], label='Validation')\n","        axes[0].legend()\n","\n","        axes[1].set_title('Train loss')\n","        axes[1].set_xlabel('Epochs')\n","        axes[1].set_ylabel('Loss')\n","        axes[1].plot(epochs, self.history['train_loss'], label='Train')\n","        axes[1].plot(epochs, self.history['val_loss'], label='Validation')\n","        plt.savefig(save)\n","        plt.show()\n","        \n","  \n","def validate(model, val_loader, use_gpu=False):\n","    true = []\n","    pred = []\n","    val_loss = []\n","\n","    criterion = nn.CrossEntropyLoss()\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for j, batch in enumerate(val_loader):\n","\n","            inputs, targets = batch\n","            if use_gpu:\n","                inputs = inputs.cuda()\n","                targets = targets.cuda()\n","\n","            output = model(inputs)\n","\n","            predictions = output.max(dim=1)[1]\n","\n","            val_loss.append(criterion(output, targets).item())\n","            true.extend(targets.data.cpu().numpy().tolist())\n","            pred.extend(predictions.data.cpu().numpy().tolist())\n","\n","    return accuracy_score(true, pred) * 100, sum(val_loss) / len(val_loss)\n","\n","\n","def train(model,train_loader, val_loader, n_epoch, batch_size, learning_rate, loss_fn, use_gpu=False):\n","    history = History()\n","\n","    criterion = loss_fn\n","    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","    for i in range(n_epoch):\n","        model.train()\n","        for j, batch in enumerate(train_loader):\n","\n","            inputs, targets = batch\n","            if use_gpu:\n","                inputs = inputs.cuda()\n","                targets = targets.cuda()\n","\n","            optimizer.zero_grad()\n","            output = model(inputs)\n","\n","            loss = criterion(output, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","        train_acc, train_loss = validate(model, train_loader, use_gpu)\n","        val_acc, val_loss = validate(model, val_loader, use_gpu)\n","        history.save(train_acc, val_acc, train_loss, val_loss)\n","        print('Epoch {} - Train acc: {:.2f} - Val acc: {:.2f} - Train loss: {:.4f} - Val loss: {:.4f}'.format(i,\n","                                                                                                              train_acc,\n","                                                                                                              val_acc,\n","                                                                                                              train_loss,\n","                                                                                                              val_loss))\n","    return history    \n","    \n","def test(model, test_loader,use_gpu=False):\n","    loader = test_loader\n","    return validate(model, loader, use_gpu)\n","\n","def save(model, f):\n","   torch.save(model, f)\n","\n","def load(f):\n","    model = torch.load(f, map_location='cpu')\n","    model.eval()\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXLANsv_Niza","colab_type":"code","colab":{}},"source":["num_classes = \n","n_epoch = \n","batch_size = \n","learning_rate = \n","model_path ="],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HS6NZJGfFsUN","colab_type":"text"},"source":["##LINEAR REGRESSION MODEL"]},{"cell_type":"code","metadata":{"id":"0KMBEpgKIDkX","colab_type":"code","colab":{}},"source":["class NUDNet():\n","    \n","    def __init__(self, input_dim, hidden_sizes, output_dim, b_norm=False, dropout=0.0):\n","        super(NUDNet, self).__init__()\n","        layers = []\n","        in_ = input_dim\n","        for out_ in hidden_sizes:\n","            layers.append(nn.Linear(in_, out_))\n","            layers.append(nn.Dropout(p=dropout))\n","            if b_norm:\n","                layers.append(nn.BatchNorm1d(out_))\n","            layers.append(nn.ReLU())\n","\n","            in_ = out_\n","            \n","        layers.append(nn.Linear(in_, output_dim))\n","        self.net = nn.Sequential(*layers)\n","\n","\n","    def forward(self, inputs):\n","        return self.net(inputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Feo4fVC5MDki","colab_type":"code","colab":{}},"source":["\n","loss_fn = nn.CrossEntropyLoss()\n","input_dim = \n","hidden_sizes = \n","output_dim = 1\n","\n","net = NUDNet(inp)\n","if use_gpu:\n","    net = net.cuda()\n","\n","history = train(model=net, train_loader, valid_loader , learning_rate=learning_rate, n_epoch=n_epoch,\n","                    use_gpu=use_gpu, loss_fn=loss_fn)\n","   \n","acc, loss = test(model=net, test_loader, batch_size=batch_size, use_gpu=use_gpu)\n","    \n","save(net, model_path )\n","\n","\n","\n","\n","loss_func = torch.nn.MSELoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AWhs870RAzjb","colab_type":"text"},"source":["## CNN\n","Convolutional neural networks model to process key frames labeled with Deep AI Nudity Detection and Skin Detection"]},{"cell_type":"markdown","metadata":{"id":"eyU5IgUrOhr4","colab_type":"text"},"source":["###VGNET"]},{"cell_type":"code","metadata":{"id":"DHsQU5SMOO60","colab_type":"code","colab":{}},"source":["class VGNet():\n","    def __init__(self, num_classes):\n","        super(VGNet, self).__init__()\n","        self.model = models.vgg19(pretrained=True)\n","        for param in self.model.parameters():\n","            param.requires_grad = False\n","        self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n","        \n","    def forward(x):\n","      # TO DO : X need to be specified. Is it a video (many frames)? I will be back here.\n","      return self.model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEMIVt_jPPO6","colab_type":"text"},"source":["###LOAD DATASET"]},{"cell_type":"markdown","metadata":{"id":"W3ggMkEjPoDv","colab_type":"text"},"source":["###TRAINING AND TESTING"]},{"cell_type":"code","metadata":{"id":"RluJQYkePavG","colab_type":"code","colab":{}},"source":["num_classes = \n","n_epoch = \n","batch_size = \n","learning_rate = \n","model_path =\n","loss_fn = nn.CrossEntropyLoss()\n","\n","net = VGNet(num_classes)\n","\n","if use_gpu:\n","    net = net.cuda()\n","\n","history = train(model=net, train_loader, valid_loader , learning_rate=learning_rate, n_epoch=n_epoch,\n","                    use_gpu=use_gpu, loss_fn=loss_fn)\n","   \n","acc, loss = test(model=net, test_loader, batch_size=batch_size, use_gpu=use_gpu)\n","    \n","save(net, model_path )\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JHjNeLk6BRRP","colab_type":"text"},"source":["## LSTM\n","Long short-term memory model to process titles of the videos associated with the key frames"]},{"cell_type":"code","metadata":{"id":"3Ea_42VfBmWJ","colab_type":"code","colab":{}},"source":["class LSTM_model(nn.Module):    \n","    def __init__(self, input_size, hidden_size, \n","                 num_layers=1, dropout=0, bidirectional=False):\n","        super(LSTM_model, self).__init__()\n","\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bidirectional = bidirectional\n","\n","        self.lstm = nn.LSTM(input_size,\n","                            hidden_size,\n","                            num_layers,\n","                            dropout=dropout,\n","                            bidirectional=bidirectional)\n","        self.linear = nn.Linear(hidden_size, 1)\n","        \n","    def forward(self, inputs, hidden): \n","        outputs, hidden = self.lstm(inputs, hidden)\n","        predictions = self.linear(outputs[-1])\n","        return predictions.squeeze(1), outputs, hidden\n","    \n","    def init_hidden(self, batch_size):\n","        num_directions = 2 if self.bidirectional else 1\n","        hidden = (torch.zeros(self.num_layers*num_directions, batch_size, self.hidden_size),\n","                  torch.zeros(self.num_layers*num_directions, batch_size, self.hidden_size))\n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eSmpsRnizROg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9K5xXqKwL6p","colab_type":"text"},"source":["## Multimodal Deep Learning Model\n","- CNN + LSTM + Linear model\n","- Input: video (frames), title of the video\n","- Output: prediction of male or female nudity labeled with context"]},{"cell_type":"code","metadata":{"id":"Dl6yhmrNzRvu","colab_type":"code","colab":{}},"source":["class multimodal(nn.Module):\n","  def __init__(self, frame, title, num_classes):\n","    super(multimodal, self).__init__()\n","    \n","    # CNN model to procee frames\n","    self.model_1 = PreNet(num_classes)\n","\n","    # LSTM model to process title\n","    self.model_2 = \n","    \n","    # Linear model to predict nudity\n","    self.model_3 = nn.Sequential(\n","       nn.Linear(100352, 10)\n","    )\n","\n","    \n","  def forward(self, x, t):\n","    # TODO: loop through the video x to get frames\n","    out1 = self.model_1(frame)\n","    \n","    out2 = self.model_2(t)\n","    \n","    # Combine outputs from CNN and LSTM models\n","    # out =\n","    \n","    # Predict male or female nudity\n","    out = self.model_3(out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TF5J6MbY2zSz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}